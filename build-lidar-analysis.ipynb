{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Kentucky lidar data\n",
    "\n",
    "ArcGIS Pro Python script to process LAS and NAIP layers in preparation for 3D analysis and visualization. This script requires that you use this geodatabase containing index layers for downloading assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ArcGIS package\n",
    "import arcpy\n",
    "# Subprocess allows us to issue commands on the command line\n",
    "import subprocess\n",
    "# Module to download files with an URL\n",
    "import urllib.request\n",
    "# Zip utlity to extract files\n",
    "from zipfile import ZipFile\n",
    "# pandas to view table and possibly analyze data in the future?\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Pick a location anywhere in Kentucky and find its latitude and longitude\n",
    "* Download and extract [index grids](https://github.com/maptimelex/wildcat-eyes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for project \n",
    "# Got to use double backslash because of other modules\n",
    "root = \"c:\\\\BoydsGIS\"\n",
    "\n",
    "# Project name - creates a folder in project directoru\n",
    "project = \"maca\"\n",
    "\n",
    "# Name of area of interest as a single point and buffer distance from point\n",
    "# aoi = f\"{root}\\\\data\\\\locations.gdb\\\\courthouse\"\n",
    "# OR \n",
    "long = -86.104057\n",
    "lat = 37.187349\n",
    "buffer_distance = 2000\n",
    "\n",
    "# NAIP edition\n",
    "naip_year = \"2018\" # 2018, 2016, 2006 (all 2-ft resolution orthophoto)\n",
    "\n",
    "############### Local assets ###############\n",
    "\n",
    "# Locations of index grids\n",
    "las_grid = f\"{root}\\\\data\\\\download_grids.gdb\\\\KY_5k_PointClound_grid\"\n",
    "naip_grid = f\"{root}\\\\data\\\\download_grids.gdb\\\\Kentucky_10K_NAIP\"\n",
    "\n",
    "# Point the script to the directory with the laszip64.exe\n",
    "las_tools = f\"{root}\\\\data\\\\lidar\\\\laszip64.exe\"\n",
    "\n",
    "# Point the script to the directory with the PotreeConverter.exe\n",
    "potree_tools = f\"{root}\\\\potree\\\\PotreeConverter.exe\"\n",
    "\n",
    "############### Project assets ###############\n",
    "\n",
    "# Output geodatabase name\n",
    "geodb = \"workspace.gdb\"\n",
    "\n",
    "# Downloads folder\n",
    "downloads = f'{root}\\\\{project}\\\\downloads\\\\'\n",
    "lidar = f'{root}\\\\{project}\\\\lidar\\\\'\n",
    "lidar_extract = f'{root}\\\\{project}\\\\lidar_extract\\\\'\n",
    "lidar_color = f'{root}\\\\{project}\\\\lidar_color\\\\'\n",
    "\n",
    "# LAS dataset name, temp list, and class codes\n",
    "las_dataset = f'{lidar}\\\\{project}.lasd'\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "spatial_reference = arcpy.Describe(las_grid).spatialReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders\n",
    "folders = [f'{root}\\\\{project}', downloads, lidar, lidar_extract, lidar_color]\n",
    "for folder in folders:\n",
    "    subprocess.run(f'mkdir {folder}', shell=True, stdout=subprocess.PIPE)\n",
    "    print(f\"mkdir {folder}\")\n",
    "\n",
    "# Create project geodatabase\n",
    "arcpy.CreateFileGDB_management(f'{root}\\\\{project}', geodb)\n",
    "\n",
    "# Create project default geodatabase\n",
    "arcpy.env.workspace = f'{root}\\\\{project}\\\\{geodb}'\n",
    "\n",
    "# Show contents of project directory\n",
    "completed = subprocess.run(f'dir {root}\\\\{project}', shell=True, stdout=subprocess.PIPE)\n",
    "print(completed.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    aoi\n",
    "    print(f\"Using {aoi}\")\n",
    "except:\n",
    "    print(f\"Creating point at lat: {lat}, long: {long}\")\n",
    "    # Create a feature class with a spatial reference of GCS WGS 1984\n",
    "    result = arcpy.management.CreateFeatureclass(\n",
    "        arcpy.env.workspace, \n",
    "        \"test\", \"POINT\", spatial_reference=4326)\n",
    "    feature_class = result[0]\n",
    "    with arcpy.da.InsertCursor(feature_class, ['SHAPE@']) as cursor:\n",
    "        cursor.insertRow([(long, lat)])\n",
    "    aoi = \"aoi\"\n",
    "    arcpy.Project_management(\"test\", aoi, spatial_reference)\n",
    "    arcpy.Delete_management (\"test\")\n",
    "\n",
    "# Buffer point\n",
    "arcpy.Buffer_analysis(aoi, f'{project}_{buffer_distance}ft', buffer_distance)\n",
    "\n",
    "# Create a temp layer to find which LAS files to download\n",
    "arcpy.Intersect_analysis ([f'{project}_{buffer_distance}ft', las_grid], \"temp\")\n",
    "\n",
    "layers = arcpy.ListFeatureClasses()\n",
    "for layer in layers:\n",
    "    print(f\"created {layer}\")\n",
    "\n",
    "# Find URLs and download them and use laszip64.exe to convert \n",
    "cursor = arcpy.da.SearchCursor(\"temp\", ['ftppath', 'LASVersion', 'Year'])\n",
    "i = 0\n",
    "las_names = []\n",
    "for row in cursor:\n",
    "    url = row[0]\n",
    "    name = url[-12:]\n",
    "    las_names.append(f'{lidar}{url[-12:-4]}.las')\n",
    "    with urllib.request.urlopen(url) as response: \n",
    "        print(f'get {url}')\n",
    "        with open(f'{downloads}{name}', 'wb') as outFile:\n",
    "            data = response.read()\n",
    "            outFile.write(data)   \n",
    "    print(f'{las_tools} -i {downloads}{name} -o {las_names[i]}')\n",
    "    completed = subprocess.run(f'{las_tools} -i {downloads}{name} -o {las_names[i]}', shell=True, stdout=subprocess.PIPE)\n",
    "    i += 1\n",
    "\n",
    "arcpy.CreateLasDataset_management (las_names, las_dataset, \"#\", \"#\", spatial_reference, True, True)  \n",
    "arcpy.LasDatasetStatistics_management (las_dataset, \"#\", f'{root}\\\\{project}\\\\stats.csv', \"#\", \"#\", \"#\")\n",
    "with open(f'{root}\\\\{project}\\\\stats.csv', encoding='utf-8') as csv:\n",
    "    reader = pd.read_csv(csv)\n",
    "    pdData = pd.DataFrame(reader)\n",
    "\n",
    "pdData[pdData[\"Category\"] == \"ClassCodes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide which class codes to add/change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default ground classes\n",
    "# consider adding water\n",
    "las_ground = [2]\n",
    "# above ground features; check location for additional classes\n",
    "las_trees = [1, 2]\n",
    "\n",
    "# Filter for ground points \n",
    "arcpy.MakeLasDatasetLayer_management (las_dataset, f'{lidar}ground', las_ground)\n",
    "# Filter for ground  and above ground points\n",
    "arcpy.MakeLasDatasetLayer_management (las_dataset, f'{lidar}trees', las_trees)\n",
    "\n",
    "# Ceate DEM and hillshade\n",
    "arcpy.LasDatasetToRaster_conversion (f'{lidar}ground', f'{project}_dem_5ft', \"#\", \"#\", \"#\", \"#\", 5)\n",
    "arcpy.HillShade_3d(f'{project}_dem_5ft', f'{project}_hillshade', 270, 55)\n",
    "\n",
    "# Create a temp layer to find which NAIP files to download\n",
    "arcpy.RasterDomain_3d (f'{project}_hillshade', 'domain', 'POLYGON')\n",
    "arcpy.Intersect_analysis (['domain', naip_grid], \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find URLs, download them and extract \n",
    "cursor = arcpy.da.SearchCursor(\"temp\", ['ftppath16', 'TileName'])\n",
    "i = 0\n",
    "naip_names = []\n",
    "if naip_year == \"2016\":\n",
    "    # NAIP files have prefix\n",
    "    naip_prefix = \"ky_2ft_naip_2016_\"\n",
    "    extension = \"jpg\"\n",
    "elif naip_year == \"2018\":\n",
    "    naip_prefix = \"KY_2FT_NAIP_2018_\"\n",
    "    extension = \"tif\"\n",
    "elif naip_year == \"2006\":\n",
    "    naip_prefix = \"ky_2ft_naip_2006_\"\n",
    "    extension = \"jpg\"\n",
    "for row in cursor:\n",
    "    url = row[0].replace(\"_2016_\", f\"_{naip_year}_\")\n",
    "    if naip_year == \"2006\":\n",
    "        name = row[1].lower()\n",
    "    else:\n",
    "        name = row[1]\n",
    "    naip_names.append(name)\n",
    "    print(f'downloading {url}...')\n",
    "    with urllib.request.urlopen(url) as response: \n",
    "        with open(f'{downloads}{name}.zip', 'wb') as outFile:\n",
    "            data = response.read()\n",
    "            outFile.write(data) \n",
    "    with ZipFile(f'{downloads}{name}.zip', 'r') as zip: \n",
    "        zip.extractall(f'{downloads}{name}')\n",
    "    print(f'{downloads}{name}\\\\{naip_prefix}{name}.{extension}')\n",
    "    arcpy.CopyRaster_management (f'{downloads}{name}\\\\{naip_prefix}{name}.{extension}', name)\n",
    "    i += 1\n",
    "    \n",
    "# If multiple NAIPs, then mosaic to new raster and clip\n",
    "print(f'Mosaic to new raster...')\n",
    "arcpy.Delete_management (f'{root}\\\\{project}\\\\{geodb}\\\\temp')\n",
    "if naip_year == \"2018\":\n",
    "    bands = 4\n",
    "else:\n",
    "    bands = 3\n",
    "if len(naip_names) > 1:\n",
    "    arcpy.MosaicToNewRaster_management (naip_names, f'{root}\\\\{project}\\\\{geodb}', \"temp\", None, \"8_BIT_UNSIGNED\", None, bands)\n",
    "    arcpy.Clip_management ('temp', '#', f'{project}_naip', 'domain')\n",
    "else:\n",
    "    arcpy.Clip_management (naip_names[0], '#', f'{project}_naip', 'domain')\n",
    "arcpy.Delete_management (f'{root}\\\\{project}\\\\{geodb}\\\\temp')\n",
    "\n",
    "# Extract LAS points in buffer and colorize\n",
    "print(f'Creating {lidar}trees...')\n",
    "arcpy.ExtractLas_3d (f'{lidar}trees', lidar, f'{project}_{buffer_distance}ft', \"#\", \"#\", \"_extract\", \"#\", \"#\", True, f'{lidar_extract}temp.lasd')\n",
    "arcpy.ColorizeLas_3d (f'{lidar_extract}temp.lasd', f'{project}_naip', 'RED Band_1; GREEN Band_2; BLUE Band_3', lidar_color, \"_color\", \"#\",  \"#\",  \"#\",  \"#\", True, f'{lidar_color}{project}_rgb.lasd')\n",
    "arcpy.LasPointStatsAsRaster_management(f'{lidar_color}{project}_rgb.lasd', \"z_range\", \"Z_RANGE\", \"CELLSIZE\", 5)\n",
    "\n",
    "# Create DSM of cliffs over 30 feet in 30-ft diameter neighborhood from bare-earth DEM\n",
    "print(f'Creating cliffs_over_30ft...')\n",
    "neighborhood = arcpy.sa.NbrCircle(3,'CELL')\n",
    "outFocalStat = arcpy.sa.FocalStatistics(f'{project}_dem_5ft', neighborhood, \"RANGE\")\n",
    "outFocalStat.save(\"focal_stats_30ft\")\n",
    "cliffs_over_30ft = arcpy.sa.Con(outFocalStat > 30, outFocalStat)\n",
    "cliffs_over_30ft.save(\"cliffs_over_30ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Potree to render point cloud\n",
    "for i in las_names:\n",
    "    with open(f'{root}\\\\{project}\\\\potree_las_list.txt', 'a+') as outFile:\n",
    "        a = i.replace(\"\\\\lidar\\\\\", \"\\\\lidar_color\\\\\")\n",
    "        b = a.replace(\".las\", \"_extract_color.las\")\n",
    "        print(b)\n",
    "        outFile.write(f\"{b}\\n\")\n",
    "print(potree_tools)\n",
    "completed = subprocess.run(f\"{potree_tools} --list-of-files {root}\\\\{project}\\\\potree_las_list.txt -o {root}\\\\{project}\\\\potree -p index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
